model:
  name: /home/work/aipr-jhna/huggingface_hub/Qwen2.5-Coder-1.5B
  type: qwen
  temperature: 0.7
  top_p: 0.9
  max_length: 2048
  tokenizer_kwargs:
    trust_remote_code: true
  model_kwargs:
    trust_remote_code: true
    torch_dtype: bfloat16
dataset:
  name: /home/work/aipr-jhna/huggingface_hub/openai_humaneval
  type: humaneval
  train_split: test[33:163]
  eval_split: test[:32]
  size: 130
  eval_size: 32
output:
  base_dir: output
  verbose: false
  save_final_model: false
  save_path: /home/work/aipr-jhna/output/maac_final
external:
  mode: level_feedback
  sandbox_slice: 1
maac:
  num_turns: 1
  critic_type: v
  num_train_epochs: 6
  per_device_train_batch_size: 1
  actor_learning_rate: 5.0e-06
  critic_learning_rate: 5.0e-06
  value_loss_coef: 0.6
  rollout_buffer_size: 4
  max_new_tokens: 256
  temperature: 0.7
  top_p: 0.9
  top_k: null
  num_agents: 2
  critic_model: null
  reward_shift: 0
  discount: 0.9
  early_termination_threshold: -0.2
  eval_interval: 4
  eval_num_samples: 32
  logging_steps: 5
wandb:
  project: HumanEval
  entity: contrl
  name: maac_he_qwen2.5-coder-1.5b-shift-0_v-value
  dir: output
  tags:
  - maac
  - humaneval
  - multi-agent
